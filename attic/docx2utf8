#!/usr/bin/env python3
"""Extract text from a Word document."""
import argparse
import re
import typing as t
import unicodedata as ud
from pathlib import Path

from docx_worker import DocxWorker  # type: ignore[import-not-found]

Strings: t.TypeAlias = t.Iterable[str]


class StopError(Exception):
    """Stop converting the file."""


class Docx2Utf8(DocxWorker):
    """Extract text from a Word document."""

    args: argparse.Namespace
    inpath: Path
    outpath: Path
    start_found: bool = False
    stop_found: bool = False
    nlines: int

    def pre_work(self) -> Path:
        """Return path to input .docx."""
        parser = argparse.ArgumentParser(description=__doc__)
        parser.add_argument("input", type=Path, help="a .docx file")
        parser.add_argument("output", type=Path, help="a text file", nargs="?")
        parser.add_argument(
            "-s", "--sentences",
            action="store_true",
            help="break text into sentences",
        )
        parser.add_argument(
            "-l", "--min-length",
            type=int,
            default=1,
            help="minimum line length in letters",
        )
        parser.add_argument(
            "--start",
            metavar="STRING",
            help="ignore text up to first occurence of STRING",
        )
        parser.add_argument(
            "--stop",
            metavar="STRING",
            help="stop after paragraph containing STRING",
        )
        self.args = parser.parse_args()
        self.inpath = self.args.input
        self.outpath = self.args.output or self.inpath.with_suffix(".txt")
        print(f"{self.inpath} -> {self.outpath}")
        return self.args.input

    def work(self) -> None:
        """Work while `self.izip` is open."""
        npars = self.nlines = 0
        with self.outpath.open("w", encoding="utf-8") as ofo:
            body = self.find(self.doc, "./w:body")
            try:
                for pno in self.xpath(body, "./w:p"):
                    npars += 1
                    ichunks = (tno.text for tno in self.pnode_tnodes(pno))
                    for ochunk in self._handle_paragraph(ichunks):
                        ofo.write(ochunk)
            except StopError:
                pass
            nchars = ofo.tell()
        print(
            f"{self.outpath}: "
            f"{npars} paragraphs(s), "
            f"{self.nlines} line(s), "
            f"{nchars} character(s).",
        )

    def _handle_paragraph(self, ichunks: Strings) -> Strings:
        """Convert one input paragraph."""
        text = "".join(ichunks)
        if self.args.sentences:
            for sentence in re.findall(r"\w[^.?!:]+(?:[.?!:]+|$)", text):
                yield from self._consider(sentence, "\n")
        else:
            yield from self._consider(text, "\n\n")

    def _consider(self, line: str, sep: str) -> Strings:
        """Consider outputting a line."""
        if self.args.start and not self.start_found:
            self.start_found = self.args.start in line
            if not self.start_found:
                return

        if self._vlen(line) >= self.args.min_length:
            yield line
            yield sep
            self.nlines += 1

        if self.args.stop:
            if self.args.stop in line:
                raise StopError

    def _vlen(self, text: str) -> int:
        """Return visible Length (or an approximation thereof)."""
        chars = [c for c in text if ud.category(c)[0] in "LNPSZ"]
        wides = [c for c in chars if ud.east_asian_width(c) in "WF"]
        return len(chars) + len(wides)


if __name__ == "__main__":
    Docx2Utf8().main()
