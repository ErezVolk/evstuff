#!/usr/bin/env python3
"""Google things."""
# pyright: reportMissingImports=false
# mypy: disable-error-code="import-untyped"
# pylint: disable=import-error

import hashlib
import json
import re
import subprocess
import urllib.parse
from collections import defaultdict
from pathlib import Path

BIN = Path.home() / "bin"
CONFIG = BIN / "ggev.json"
HISTORY = BIN / "ggev.history"

with CONFIG.open(encoding="utf-8") as _fo:
    config = json.load(_fo)

BLACKLIST_PREFIXES = set(config.get("BLACKLIST_PREFIXES", []))

PURPLE = "\033[95m"
CYAN = "\033[96m"
DARKCYAN = "\033[36m"
BLUE = "\033[94m"
GREEN = "\033[92m"
YELLOW = "\033[93m"
RED = "\033[91m"
BOLD = "\033[1m"
UNDERLINE = "\033[4m"
END = "\033[0m"


class SearchError(Exception):
    """Search engine says NO."""


def main() -> None:
    """Google things."""
    try:
        hits = {}
        for kwargs in config["SEARCHES"]:
            hits.update(ddg(**kwargs))
    except SearchError as ge:
        print(ge)
        return

    for hit in hits.values():
        abstract = hit["abstract"]
        abstract = re.sub(
            r"^\s*—\s*(לפני |\d+ ב).*$",
            r"",
            abstract,
        )
        hit["md5"] = md5sum(abstract)

    history = defaultdict(set)
    try:
        with HISTORY.open(encoding="utf-8") as fo:
            for line in fo:
                url, *md5s = line.strip().split("\t")
                history[url] = set(md5s)
    except FileNotFoundError:
        pass

    added = []
    for url, hit in hits.items():
        if hit["md5"] not in history[url]:
            added.append(url)
            history[url].add(hit["md5"])

    if not added:
        print("NO NEWS.")
    else:
        for n, url in enumerate(sorted(added), 1):
            hit = hits[url]
            title = hit["title"]
            print(f"{n}. {BOLD}{title}{END}")
            print(urllib.parse.unquote(url))
            print()
            print(hit["abstract"])
            print()

        with HISTORY.open("w", encoding="utf-8") as fo:
            for url, md5s in history.items():
                fo.write("\t".join([url, *list(md5s)]))
                fo.write("\n")


GG2DDG_LANG = {
    "iv": "il-he",
}

GG2DDG_TIME = {
    "m1": "m",
    "w1": "w",
}


def ddg(
    query: str,
    lang: str | None = None,
    timeframe: str | None = "m1",
) -> dict[str, dict]:
    """Call DuckDuckGo."""
    cmd = ["ddgr", "--json"]
    if lang is not None:
        cmd.append("--reg")
        cmd.append(GG2DDG_LANG[lang])
    if timeframe:
        cmd.append("--time")
        cmd.append(GG2DDG_TIME[timeframe])
    cmd.append(query)
    return call_searcher(cmd)


def call_searcher(cmd: list[str]) -> dict[str, dict]:
    """Call any kind of googler-like searcher app."""
    out = subprocess.run(cmd, capture_output=True, check=False)
    if out.returncode != 0:
        raise SearchError(out.stderr.decode())
    return {
        hit["url"]: hit
        for hit in json.loads(out.stdout)
        if not blacklisted(hit["url"])
    }


def blacklisted(url: str) -> bool:
    """Check if URL is blacklisted."""
    return any(url.startswith(prefix) for prefix in BLACKLIST_PREFIXES)


def md5sum(text: str) -> str:
    """Calculate MD5."""
    return hashlib.md5(text.encode("utf-8")).hexdigest()


if __name__ == "__main__":
    main()
